{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "\n",
    "import roma\n",
    "import kornia\n",
    "import utils.colmap as colmap_utils\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from vggt.models.vggt import VGGT\n",
    "from vggt.utils.load_fn import load_and_preprocess_images_ratio, load_and_preprocess_images_square\n",
    "from vggt.utils.pose_enc import pose_encoding_to_extri_intri\n",
    "from vggt.utils.geometry import unproject_depth_map_to_point_map\n",
    "\n",
    "from utils.umeyama import umeyama\n",
    "from utils.metric_torch import evaluate_auc, evaluate_pcd\n",
    "\n",
    "torch._dynamo.config.accumulated_cache_size_limit = 512\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# bfloat16 is supported on Ampere GPUs (Compute Capability 8.0+) \n",
    "dtype = torch.bfloat16 if torch.cuda.get_device_capability()[0] >= 8 else torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_VGGT(images, device, dtype):\n",
    "    # images: [B, 3, H, W]\n",
    "\n",
    "    # Run VGGT for camera and depth estimation\n",
    "    model = VGGT()\n",
    "    _URL = \"https://huggingface.co/facebook/VGGT-1B/resolve/main/model.pt\"\n",
    "    model.load_state_dict(torch.hub.load_state_dict_from_url(_URL))\n",
    "    model.eval()\n",
    "    model = model.to(device).to(dtype)\n",
    "    print(f\"Model loaded\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(images.to(device, dtype), verbose=True)\n",
    "        extrinsic, intrinsic = pose_encoding_to_extri_intri(predictions['pose_enc'], images.shape[-2:])\n",
    "        extrinsic = extrinsic.squeeze(0).cpu().numpy()\n",
    "        intrinsic = intrinsic.squeeze(0).cpu().numpy()\n",
    "        depth_map = predictions['depth'].squeeze(0).cpu().numpy()\n",
    "        depth_conf = predictions['depth_conf'].squeeze(0).cpu().numpy()\n",
    "    \n",
    "    return extrinsic, intrinsic, depth_map, depth_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image paths and preprocess them\n",
    "data_dir = \"../data/free/free_dataset/hydrant\"\n",
    "sparse_dir_gt = os.path.join(data_dir, \"sparse\", \"0\")\n",
    "dust_dir = os.path.join(data_dir, \"mast3r\")\n",
    "images_dir = os.path.join(data_dir, \"images\")\n",
    "\n",
    "cameras_gt = colmap_utils.read_cameras_binary(os.path.join(sparse_dir_gt, \"cameras.bin\"))\n",
    "images_gt = colmap_utils.read_images_binary(os.path.join(sparse_dir_gt, \"images.bin\"))\n",
    "pcd_gt = colmap_utils.read_points3D_binary(os.path.join(sparse_dir_gt, \"points3D.bin\"))\n",
    "# images_gt = dict(sorted(images_gt.items(), key=lambda item: item[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_gt_keys = list(images_gt.keys())\n",
    "random.seed(42)\n",
    "random.shuffle(images_gt_keys)\n",
    "images_gt_updated = {id: images_gt[id] for id in list(images_gt_keys)}\n",
    "image_path_list = [os.path.join(images_dir, images_gt_updated[id].name) for id in images_gt_updated.keys()]\n",
    "base_image_path_list = [os.path.basename(path) for path in image_path_list]\n",
    "vggt_fixed_resolution = 518\n",
    "images, original_coords = load_and_preprocess_images_ratio(image_path_list, vggt_fixed_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGGT results loaded\n"
     ]
    }
   ],
   "source": [
    "# Run VGGT to estimate camera and depth\n",
    "# Run with 518x518 images\n",
    "if not os.path.exists(f\"./vggt_results_{data_dir.split('/')[-1]}.npz\"):\n",
    "    extrinsic, intrinsic, depth_map, depth_conf = run_VGGT(images, device, dtype)\n",
    "    output_dict = {\n",
    "        \"extrinsic\": extrinsic,\n",
    "        \"intrinsic\": intrinsic,\n",
    "        \"depth_map\": depth_map,\n",
    "        \"depth_conf\": depth_conf,\n",
    "        \"base_image_path_list\": base_image_path_list\n",
    "    }\n",
    "    np.savez(f\"./vggt_results_{data_dir.split('/')[-1]}.npz\", output_dict)\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    output_dict = np.load(f\"./vggt_results_{data_dir.split('/')[-1]}.npz\", allow_pickle=True)['arr_0'].item()\n",
    "\n",
    "\n",
    "inverse_idx = [images_gt_keys.index(key) for key in list(images_gt.keys())]\n",
    "extrinsic = output_dict['extrinsic'][inverse_idx]\n",
    "intrinsic = output_dict['intrinsic'][inverse_idx]\n",
    "depth_map = output_dict['depth_map'][inverse_idx]\n",
    "depth_conf = output_dict['depth_conf'][inverse_idx]\n",
    "images = images[inverse_idx]\n",
    "original_coords = original_coords[inverse_idx]\n",
    "images_gt_keys = list(images_gt.keys())\n",
    "images_gt_updated = {id: images_gt[id] for id in list(images_gt_keys)}\n",
    "image_path_list = [os.path.join(images_dir, images_gt_updated[id].name) for id in images_gt_updated.keys()]\n",
    "base_image_path_list = [os.path.basename(path) for path in image_path_list]\n",
    "print(\"VGGT results loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    --  Umeyama Scale:  0.10716810800939235\n",
      "    --  Umeyama Rotation: \n",
      " [[ 0.84579078 -0.13225682  0.51686175]\n",
      " [ 0.14452347  0.98936105  0.01666428]\n",
      " [-0.51356685  0.06060417  0.85590667]]\n",
      "    --  Umeyama Translation: \n",
      " [[-0.00494413]\n",
      " [ 0.0340953 ]\n",
      " [-0.19855241]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7572/4132866928.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  fl_gt = torch.tensor([cameras_gt[image.camera_id].params[0:2] for image in images_gt_updated.values()], device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    --  Pair Rot   Error (Deg) of Vanilla:       1.97\n",
      "    --  Pair Trans Error (Deg) of Vanilla:      10.66\n",
      "    --  AUC at 30: 0.6842\n"
     ]
    }
   ],
   "source": [
    "fl_gt = torch.tensor([cameras_gt[image.camera_id].params[0:2] for image in images_gt_updated.values()], device=device)\n",
    "translation_gt = torch.tensor([image.tvec for image in images_gt_updated.values()], device=device)\n",
    "rotation_gt = torch.tensor([colmap_utils.qvec2rotmat(image.qvec) for image in images_gt_updated.values()], device=device)\n",
    "\n",
    "# gt w2c\n",
    "gt_se3 = torch.eye(4, device=device).unsqueeze(0).repeat(len(images_gt_updated), 1, 1)\n",
    "gt_se3[:, :3, :3] = rotation_gt\n",
    "gt_se3[:, 3, :3] = translation_gt\n",
    "\n",
    "# pred w2c\n",
    "pred_se3 = torch.eye(4, device=device).unsqueeze(0).repeat(len(images_gt_updated), 1, 1)\n",
    "pred_se3[:, :3, :3] = torch.tensor(extrinsic[:, :3, :3], device=device)\n",
    "pred_se3[:, 3, :3] = torch.tensor(extrinsic[:, :3, 3], device=device)\n",
    "\n",
    "results = evaluate_auc(gt_se3, pred_se3, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Calculate Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.opt as opt_utils\n",
    "\n",
    "@torch.inference_mode()\n",
    "def extract_matches(extrinsic, intrinsic, images, base_image_path_list, max_query_pts=4096, batch_size=256, pairing_angle_threshold=30):\n",
    "\n",
    "    xfeat = torch.hub.load('/home/jing_li/.cache/torch/hub/verlab_accelerated_features_main', \n",
    "                           'XFeat', source='local', pretrained=True, top_k=max_query_pts)  # TODO: remove the local path\n",
    "\n",
    "    pairs, pairs_cnt = opt_utils.image_pair_candidates(extrinsic, pairing_angle_threshold, unique_pairs=True)\n",
    "    print(\"Total candidate image pairs found: \", pairs_cnt)\n",
    "\n",
    "    indexes_i = list(range(len(base_image_path_list)-1))  # the last image \n",
    "    # indexes_j = [np.random.choice(pairs[idx_i], min(20, len(pairs[idx_i])), replace=False) for idx_i in indexes_i]\n",
    "    indexes_j = [pairs[idx_i] for idx_i in indexes_i]\n",
    "    indexes_i = [np.array([idx_i] * len(indexes_j[idx_i])) for idx_i in indexes_i]\n",
    "    indexes_i = np.concatenate(indexes_i).tolist()\n",
    "    indexes_j = np.concatenate(indexes_j).tolist()\n",
    "\n",
    "    matches_list = []\n",
    "\n",
    "    for i in tqdm(range(0, len(indexes_i), batch_size), desc=\"Matching image pairs...\"):\n",
    "        indexes_i_batch = indexes_i[i:i + batch_size]\n",
    "        indexes_j_batch = indexes_j[i:i + batch_size]\n",
    "        \n",
    "        # Extract features for the batch\n",
    "        images_i = images[indexes_i_batch]\n",
    "        images_j = images[indexes_j_batch]\n",
    "        \n",
    "        # Match features\n",
    "        matches_batch = xfeat.match_xfeat_star(images_i, images_j)\n",
    "        matches_list.extend(matches_batch)\n",
    "\n",
    "    num_matches = [len(m) for m in matches_list]\n",
    "\n",
    "    indexes_i_expanded = []\n",
    "    indexes_j_expanded = []\n",
    "\n",
    "    for idx, n in enumerate(num_matches):\n",
    "        indexes_i_expanded.append(np.array([indexes_i[idx]] * n, dtype=np.int64))\n",
    "        indexes_j_expanded.append(np.array([indexes_j[idx]] * n, dtype=np.int64))\n",
    "    indexes_i_expanded = np.concatenate(indexes_i_expanded)\n",
    "    indexes_j_expanded = np.concatenate(indexes_j_expanded)\n",
    "\n",
    "    image_names_i = np.array(base_image_path_list)[indexes_i_expanded]\n",
    "    image_names_j = np.array(base_image_path_list)[indexes_j_expanded]\n",
    "\n",
    "    corr_points_i = torch.cat([matches_list[k][:, :2] for k in range(len(matches_list))], dim=0).cpu()\n",
    "    corr_points_j = torch.cat([matches_list[k][:, 2:] for k in range(len(matches_list))], dim=0).cpu()\n",
    "\n",
    "    intrinsic_i = np.zeros((corr_points_i.shape[0], 4, 4), dtype=np.float32)\n",
    "    intrinsic_j = np.zeros((corr_points_j.shape[0], 4, 4), dtype=np.float32)\n",
    "    intrinsic_i[:, :3, :3] = intrinsic[indexes_i_expanded]\n",
    "    intrinsic_j[:, :3, :3] = intrinsic[indexes_j_expanded]\n",
    "    intrinsic_i[:, 3, 3] = 1.0\n",
    "    intrinsic_j[:, 3, 3] = 1.0\n",
    "\n",
    "    extrinsic_i = np.zeros((corr_points_i.shape[0], 4, 4), dtype=np.float32)\n",
    "    extrinsic_j = np.zeros((corr_points_j.shape[0], 4, 4), dtype=np.float32)\n",
    "    extrinsic_i[:, :3, :4] = extrinsic[indexes_i_expanded]\n",
    "    extrinsic_j[:, :3, :4] = extrinsic[indexes_j_expanded]\n",
    "    extrinsic_i[:, 3, 3] = 1.0\n",
    "    extrinsic_j[:, 3, 3] = 1.0\n",
    "\n",
    "    device = corr_points_i.device\n",
    "\n",
    "    intrinsic_i_tensor = torch.FloatTensor(intrinsic_i).to(device)\n",
    "    intrinsic_j_tensor = torch.FloatTensor(intrinsic_j).to(device)\n",
    "    extrinsic_i_tensor = torch.FloatTensor(extrinsic_i).to(device)\n",
    "    extrinsic_j_tensor = torch.FloatTensor(extrinsic_j).to(device)\n",
    "\n",
    "    P_i = intrinsic_i_tensor @ extrinsic_i_tensor\n",
    "    P_j = intrinsic_j_tensor @ extrinsic_j_tensor\n",
    "    Fm = kornia.geometry.epipolar.fundamental_from_projections(P_i[:, :3], P_j[:, :3])\n",
    "    err = kornia.geometry.symmetrical_epipolar_distance(corr_points_i[:, None, :2], corr_points_j[:, None, :2], Fm, squared=False, eps=1e-08)\n",
    "    \n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(err.cpu().numpy(), bins=100, density=True, range=(0, 20))\n",
    "    plt.title(f\"Symmetrical Epipolar Distance Distribution of {len(err)} correspondences, average: {err.mean().item():.3f}, std: {err.std().item():.3f}\")\n",
    "    plt.xlabel(\"Distance\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    hist, bin_edges = torch.histogram(err.cpu(), bins=100, range=(0, 20), density=True)  # move to cpu to avoid CUDA \"backend\"\n",
    "    corr_weights = torch.zeros_like(err)\n",
    "    for i in range(len(bin_edges) - 1):\n",
    "        mask = (err >= bin_edges[i]) & (err < bin_edges[i + 1])\n",
    "        if torch.any(mask):\n",
    "            corr_weights[mask] = (hist[i] * (bin_edges[i + 1] - bin_edges[i])) / (bin_edges[-1] - bin_edges[0])\n",
    "    corr_weights /= corr_weights.mean()\n",
    "    \n",
    "    # set corr_weights to 0 for points outside the image frame\n",
    "    in_frame_i = (corr_points_i[..., 0] > images.shape[-1]) & (corr_points_i[..., 0] < 0) & \\\n",
    "                    (corr_points_i[..., 1] > images.shape[-2]) & (corr_points_i[..., 1] < 0)\n",
    "    in_frame_j = (corr_points_j[..., 0] > images.shape[-1]) & (corr_points_j[..., 0] < 0) & \\\n",
    "                    (corr_points_j[..., 1] > images.shape[-2]) & (corr_points_j[..., 1] < 0)\n",
    "    corr_weights[in_frame_i & in_frame_j] = 0.0\n",
    "    \n",
    "    # rearrange corr_points_i_normalized and corr_points_j_normalized to (P, N, 2)\n",
    "    P, N = len(num_matches), max(num_matches)\n",
    "    corr_points_i_batched = torch.zeros((P, N, 2), dtype=corr_points_i.dtype, device=corr_points_i.device)\n",
    "    corr_points_j_batched = torch.zeros((P, N, 2), dtype=corr_points_j.dtype, device=corr_points_j.device)\n",
    "    corr_weights_batched = torch.zeros((P, N, 1), dtype=corr_weights.dtype, device=corr_weights.device)\n",
    "    image_names_i_batched = np.zeros((P), dtype=image_names_i.dtype)\n",
    "    image_names_j_batched = np.zeros((P), dtype=image_names_j.dtype)\n",
    "\n",
    "    start_idx = 0\n",
    "    for p in range(P):\n",
    "        end_idx = start_idx + num_matches[p]\n",
    "        corr_points_i_batched[p, :num_matches[p]] = corr_points_i[start_idx:end_idx]\n",
    "        corr_points_j_batched[p, :num_matches[p]] = corr_points_j[start_idx:end_idx]\n",
    "        corr_weights_batched[p, :num_matches[p]] = corr_weights[start_idx:end_idx]\n",
    "        image_names_i_batched[p] = image_names_i[start_idx]\n",
    "        image_names_j_batched[p] = image_names_j[start_idx]\n",
    "        assert (image_names_i[start_idx:end_idx] == image_names_i_batched[p]).all()\n",
    "        assert (image_names_j[start_idx:end_idx] == image_names_j_batched[p]).all()\n",
    "        start_idx = end_idx\n",
    "    \n",
    "    output_dict = {\n",
    "        \"corr_points_i\": corr_points_i_batched,\n",
    "        \"corr_points_j\": corr_points_j_batched,\n",
    "        \"corr_weights\": corr_weights_batched,\n",
    "        \"image_names_i\": image_names_i_batched,\n",
    "        \"image_names_j\": image_names_j_batched,\n",
    "        \"num_matches\": num_matches,\n",
    "        \"epipolar_err\": err.median().item()\n",
    "    }\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jing_li/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m xfeat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/jing_li/.cache/torch/hub/verlab_accelerated_features_main\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      6\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXFeat\u001b[39m\u001b[38;5;124m'\u001b[39m, source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m'\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, top_k\u001b[38;5;241m=\u001b[39mmax_query_pts)  \u001b[38;5;66;03m# TODO: remove the local path\u001b[39;00m\n\u001b[1;32m      8\u001b[0m pairs, pairs_cnt \u001b[38;5;241m=\u001b[39m opt_utils\u001b[38;5;241m.\u001b[39mimage_pair_candidates(extrinsic, \u001b[38;5;241m30\u001b[39m, unique_pairs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m query_frame_indexes \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_rank_by_dino\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_frame_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_query_pts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal candidate image pairs found: \u001b[39m\u001b[38;5;124m\"\u001b[39m, pairs_cnt)\n",
      "File \u001b[0;32m/data1/yang_liu/python_workspace/vggt/notebooks/../vggt/dependency/vggsfm_utils.py:79\u001b[0m, in \u001b[0;36mgenerate_rank_by_dino\u001b[0;34m(images, query_frame_num, image_size, model_name, device, spatial_similarity)\u001b[0m\n\u001b[1;32m     77\u001b[0m resnet_mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(_RESNET_MEAN, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     78\u001b[0m resnet_std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(_RESNET_STD, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m images_resnet_norm \u001b[38;5;241m=\u001b[39m (\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mresnet_mean\u001b[49m) \u001b[38;5;241m/\u001b[39m resnet_std\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     82\u001b[0m     frame_feat \u001b[38;5;241m=\u001b[39m dino_v2_model(images_resnet_norm, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "from vggt.dependency.track_predict import generate_rank_by_dino\n",
    "\n",
    "batch_size = 256\n",
    "max_query_pts = 4096\n",
    "xfeat = torch.hub.load('/home/jing_li/.cache/torch/hub/verlab_accelerated_features_main', \n",
    "                           'XFeat', source='local', pretrained=True, top_k=max_query_pts)  # TODO: remove the local path\n",
    "\n",
    "pairs, pairs_cnt = opt_utils.image_pair_candidates(extrinsic, 30, unique_pairs=True)\n",
    "query_frame_indexes = generate_rank_by_dino(images, query_frame_num=max_query_pts, device=device)\n",
    "\n",
    "print(\"Total candidate image pairs found: \", pairs_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total candidate image pairs found:  2948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching image pairs...: 100%|██████████| 12/12 [09:21<00:00, 46.82s/it]  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved matches to ./matches_hydrant.pt\n"
     ]
    }
   ],
   "source": [
    "target_path = os.path.join(\"./\", f\"matches_{data_dir.split('/')[-1]}.pt\")\n",
    "if os.path.exists(target_path):\n",
    "    print(f\"Found existing matches at {target_path}, loading it\")\n",
    "    match_outputs = torch.load(target_path)\n",
    "else:\n",
    "    match_outputs = extract_matches(extrinsic, intrinsic, images, base_image_path_list, 2048, pairing_angle_threshold=30)\n",
    "    match_outputs[\"original_width\"] = images.shape[-1]\n",
    "    match_outputs[\"original_height\"] = images.shape[-2]\n",
    "   \n",
    "    torch.save(match_outputs, target_path)\n",
    "    print(f\"Saved matches to {target_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycolmap\n",
    "import copy\n",
    "from vggt.dependency.projection import project_3D_points_np\n",
    "from vggt.dependency.np_to_pycolmap import _build_pycolmap_intri\n",
    "\n",
    "def rename_colmap_recons_and_rescale_camera(\n",
    "    reconstruction, image_paths, original_coords, img_size, shift_point2d_to_original_res=False, shared_camera=False\n",
    "):\n",
    "    rescale_camera = True\n",
    "\n",
    "    for pyimageid in reconstruction.images:\n",
    "        # Reshaped the padded&resized image to the original size\n",
    "        # Rename the images to the original names\n",
    "        pyimage = reconstruction.images[pyimageid]\n",
    "        pycamera = reconstruction.cameras[pyimage.camera_id]\n",
    "        pyimage.name = image_paths[pyimageid - 1]\n",
    "\n",
    "        if rescale_camera:\n",
    "            # Rescale the camera parameters\n",
    "            pred_params = copy.deepcopy(pycamera.params)\n",
    "\n",
    "            real_image_size = original_coords[pyimageid - 1, -2:]\n",
    "            resize_ratio = max(real_image_size) / img_size\n",
    "            pred_params = pred_params * resize_ratio\n",
    "            real_pp = real_image_size / 2\n",
    "            pred_params[-2:] = real_pp  # center of the image\n",
    "\n",
    "            pycamera.params = pred_params\n",
    "            pycamera.width = real_image_size[0]\n",
    "            pycamera.height = real_image_size[1]\n",
    "\n",
    "        if shift_point2d_to_original_res:\n",
    "            # Also shift the point2D to original resolution\n",
    "            top_left = original_coords[pyimageid - 1, :2]\n",
    "\n",
    "            for point2D in pyimage.points2D:\n",
    "                point2D.xy = (point2D.xy - top_left) * resize_ratio\n",
    "\n",
    "        if shared_camera:\n",
    "            # If shared_camera, all images share the same camera\n",
    "            # no need to rescale any more\n",
    "            rescale_camera = False\n",
    "\n",
    "    return reconstruction\n",
    "\n",
    "def batch_np_matrix_to_pycolmap_xfeat(\n",
    "    points3d,\n",
    "    extrinsics,\n",
    "    intrinsics,\n",
    "    tracks,\n",
    "    image_size,\n",
    "    masks=None,\n",
    "    max_reproj_error=None,\n",
    "    max_points3D_val=3000,\n",
    "    shared_camera=False,\n",
    "    camera_type=\"SIMPLE_PINHOLE\",\n",
    "    extra_params=None,\n",
    "    min_inlier_per_frame=64,\n",
    "    points_rgb=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert Batched NumPy Arrays to PyCOLMAP\n",
    "\n",
    "    Check https://github.com/colmap/pycolmap for more details about its format\n",
    "\n",
    "    NOTE that colmap expects images/cameras/points3D to be 1-indexed\n",
    "    so there is a +1 offset between colmap index and batch index\n",
    "\n",
    "\n",
    "    NOTE: different from VGGSfM, this function:\n",
    "    1. Use np instead of torch\n",
    "    2. Frame index and camera id starts from 1 rather than 0 (to fit the format of PyCOLMAP)\n",
    "    \"\"\"\n",
    "    # points3d: Px3\n",
    "    # extrinsics: Nx3x4\n",
    "    # intrinsics: Nx3x3\n",
    "    # tracks: NxPx2\n",
    "    # masks: NxP\n",
    "    # image_size: 2, assume all the frames have been padded to the same size\n",
    "    # where N is the number of frames and P is the number of tracks\n",
    "\n",
    "    N, P, _ = tracks.shape\n",
    "    assert len(extrinsics) == N\n",
    "    assert len(intrinsics) == N\n",
    "    assert len(points3d) == P\n",
    "    assert image_size.shape[0] == 2\n",
    "\n",
    "    reproj_mask = None\n",
    "\n",
    "    if max_reproj_error is not None:\n",
    "        projected_points_2d, projected_points_cam = project_3D_points_np(points3d, extrinsics, intrinsics)\n",
    "        projected_diff = np.linalg.norm(projected_points_2d - tracks, axis=-1)\n",
    "        projected_points_2d[projected_points_cam[:, -1] <= 0] = 1e6\n",
    "        reproj_mask = projected_diff < max_reproj_error\n",
    "\n",
    "    if masks is not None and reproj_mask is not None:\n",
    "        masks = np.logical_and(masks, reproj_mask)\n",
    "    elif masks is not None:\n",
    "        masks = masks\n",
    "    else:\n",
    "        masks = reproj_mask\n",
    "\n",
    "    assert masks is not None\n",
    "\n",
    "    if masks.sum(1).min() < min_inlier_per_frame:\n",
    "        print(f\"Not enough inliers per frame, skip BA.\")\n",
    "        return None, None\n",
    "\n",
    "    # Reconstruction object, following the format of PyCOLMAP/COLMAP\n",
    "    reconstruction = pycolmap.Reconstruction()\n",
    "\n",
    "    inlier_num = masks.sum(0)\n",
    "    valid_mask = inlier_num >= 2  # a track is invalid if without two inliers\n",
    "    valid_idx = np.nonzero(valid_mask)[0]\n",
    "\n",
    "    # Only add 3D points that have sufficient 2D points\n",
    "    for vidx in valid_idx:\n",
    "        # Use RGB colors if provided, otherwise use zeros\n",
    "        rgb = points_rgb[vidx] if points_rgb is not None else np.zeros(3)\n",
    "        reconstruction.add_point3D(points3d[vidx], pycolmap.Track(), rgb)\n",
    "\n",
    "    num_points3D = len(valid_idx)\n",
    "    camera = None\n",
    "    # frame idx\n",
    "    for fidx in range(N):\n",
    "        # set camera\n",
    "        if camera is None or (not shared_camera):\n",
    "            pycolmap_intri = _build_pycolmap_intri(fidx, intrinsics, camera_type, extra_params)\n",
    "\n",
    "            camera = pycolmap.Camera(\n",
    "                model=camera_type, width=image_size[0], height=image_size[1], params=pycolmap_intri, camera_id=fidx + 1\n",
    "            )\n",
    "\n",
    "            # add camera\n",
    "            reconstruction.add_camera(camera)\n",
    "\n",
    "        # set image\n",
    "        cam_from_world = pycolmap.Rigid3d(\n",
    "            pycolmap.Rotation3d(extrinsics[fidx][:3, :3]), extrinsics[fidx][:3, 3]\n",
    "        )  # Rot and Trans\n",
    "\n",
    "        image = pycolmap.Image(\n",
    "            id=fidx + 1, name=f\"image_{fidx + 1}\", camera_id=camera.camera_id, cam_from_world=cam_from_world\n",
    "        )\n",
    "\n",
    "        points2D_list = []\n",
    "\n",
    "        point2D_idx = 0\n",
    "\n",
    "        # NOTE point3D_id start by 1\n",
    "        for point3D_id in range(1, num_points3D + 1):\n",
    "            original_track_idx = valid_idx[point3D_id - 1]\n",
    "\n",
    "            if (reconstruction.points3D[point3D_id].xyz < max_points3D_val).all():\n",
    "                if masks[fidx][original_track_idx]:\n",
    "                    # It seems we don't need +0.5 for BA\n",
    "                    point2D_xy = tracks[fidx][original_track_idx]\n",
    "                    # Please note when adding the Point2D object\n",
    "                    # It not only requires the 2D xy location, but also the id to 3D point\n",
    "                    points2D_list.append(pycolmap.Point2D(point2D_xy, point3D_id))\n",
    "\n",
    "                    # add element\n",
    "                    track = reconstruction.points3D[point3D_id].track\n",
    "                    track.add_element(fidx + 1, point2D_idx)\n",
    "                    point2D_idx += 1\n",
    "\n",
    "        assert point2D_idx == len(points2D_list)\n",
    "\n",
    "        try:\n",
    "            image.points2D = pycolmap.ListPoint2D(points2D_list)\n",
    "            image.registered = True\n",
    "        except:\n",
    "            print(f\"frame {fidx + 1} is out of BA\")\n",
    "            image.registered = False\n",
    "\n",
    "        # add image\n",
    "        reconstruction.add_image(image)\n",
    "\n",
    "    return reconstruction, valid_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "\n",
    "with torch.no_grad():\n",
    "    # make K, w2cam, cam2w\n",
    "    points_3d = torch.tensor(unproject_depth_map_to_point_map(depth_map, extrinsic, intrinsic), dtype=images.dtype)  # (N, H, W, 3)\n",
    "    imsizes = torch.tensor([images.shape[-1], images.shape[-2]]).float()\n",
    "    corr_points_i = match_outputs[\"corr_points_i\"].clone()\n",
    "    corr_points_j = match_outputs[\"corr_points_j\"].clone()\n",
    "    corr_weights = match_outputs[\"corr_weights\"].clone()\n",
    "    num_matches = match_outputs[\"num_matches\"]\n",
    "    indexes_i = [base_image_path_list.index(img_name) for img_name in match_outputs[\"image_names_i\"]]\n",
    "    indexes_j = [base_image_path_list.index(img_name) for img_name in match_outputs[\"image_names_j\"]]\n",
    "\n",
    "    depth_map_tensor = torch.tensor(depth_map)  # [B, H, W]\n",
    "    \n",
    "    corr_points_i_normalized = corr_points_i / imsizes[None, None, :] * 2 - 1\n",
    "    corr_points_j_normalized = corr_points_j / imsizes[None, None, :] * 2 - 1\n",
    "\n",
    "    depths_i_list, depths_j_list, batch_size = [], [], 16\n",
    "    rgbs_i_list, rgbs_j_list = [], []\n",
    "    points_i_list, points_j_list = [], []\n",
    "    for start_idx in range(0, len(corr_points_i_normalized), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(corr_points_i_normalized))\n",
    "        depths_i_list.append(F.grid_sample(\n",
    "            depth_map_tensor[indexes_i[start_idx:end_idx]].permute(0, 3, 1, 2),\n",
    "            corr_points_i_normalized[start_idx:end_idx, None],\n",
    "            align_corners=True,\n",
    "            mode='bilinear'\n",
    "        ).squeeze(1, 2))\n",
    "\n",
    "        depths_j_list.append(F.grid_sample(\n",
    "            depth_map_tensor[indexes_j[start_idx:end_idx]].permute(0, 3, 1, 2),\n",
    "            corr_points_j_normalized[start_idx:end_idx, None],\n",
    "            align_corners=True,\n",
    "            mode='bilinear'\n",
    "        ).squeeze(1, 2))\n",
    "\n",
    "        rgbs_i_list.append(F.grid_sample(\n",
    "            images[indexes_i[start_idx:end_idx]],\n",
    "            corr_points_i_normalized[start_idx:end_idx, None],\n",
    "            align_corners=True,\n",
    "            mode='bilinear'\n",
    "        ).squeeze(2).permute(0, 2, 1))\n",
    "\n",
    "        rgbs_j_list.append(F.grid_sample(\n",
    "            images[indexes_j[start_idx:end_idx]],\n",
    "            corr_points_j_normalized[start_idx:end_idx, None],\n",
    "            align_corners=True,\n",
    "            mode='bilinear'\n",
    "        ).squeeze(2).permute(0, 2, 1))\n",
    "\n",
    "        points_i_list.append(F.grid_sample(\n",
    "            points_3d[indexes_i[start_idx:end_idx]].permute(0, 3, 1, 2),\n",
    "            corr_points_i_normalized[start_idx:end_idx, None],\n",
    "            align_corners=True,\n",
    "            mode='bilinear'\n",
    "        ).squeeze(2).permute(0, 2, 1))\n",
    "\n",
    "        points_j_list.append(F.grid_sample(\n",
    "            points_3d[indexes_j[start_idx:end_idx]].permute(0, 3, 1, 2),\n",
    "            corr_points_j_normalized[start_idx:end_idx, None],\n",
    "            align_corners=True,\n",
    "            mode='bilinear'\n",
    "        ).squeeze(2).permute(0, 2, 1))\n",
    "\n",
    "    \n",
    "    depths_i = torch.cat(depths_i_list, dim=0).squeeze(-1)\n",
    "    depths_j = torch.cat(depths_j_list, dim=0).squeeze(-1)\n",
    "\n",
    "    rgbs_i = torch.cat(rgbs_i_list, dim=0)\n",
    "    rgbs_j = torch.cat(rgbs_j_list, dim=0)\n",
    "\n",
    "    points_i = torch.cat(points_i_list, dim=0)\n",
    "    points_j = torch.cat(points_j_list, dim=0)\n",
    "    \n",
    "    cam2w = torch.zeros_like(torch.tensor(extrinsic))  # (N, 3, 4)\n",
    "    cam2w[:, :3, :3] = torch.tensor(extrinsic[:, :3, :3]).permute(0, 2, 1)\n",
    "    cam2w[:, :, 3:] = -cam2w[:, :3, :3] @ torch.tensor(extrinsic[:, :, 3:])\n",
    "\n",
    "    Ks_i = torch.tensor(intrinsic[indexes_i])\n",
    "    Ks_j = torch.tensor(intrinsic[indexes_j])\n",
    "    cam2w_i = cam2w[indexes_i]  # (N, 3, 4)\n",
    "    cam2w_j = cam2w[indexes_j]  # (N, 3, 4)\n",
    "    \n",
    "    cam_coords_i = torch.stack([\n",
    "        (corr_points_i[..., 0] - Ks_i[:, None, 0, 2]) / Ks_i[:, None, 0, 0] * depths_i,\n",
    "        (corr_points_i[..., 1] - Ks_i[:, None, 1, 2]) / Ks_i[:, None, 1, 1] * depths_i,\n",
    "        depths_i\n",
    "    ], dim=-1)  # (N, P, 3)\n",
    "    cam_coords_j = torch.stack([\n",
    "        (corr_points_j[..., 0] - Ks_j[:, None, 0, 2]) / Ks_j[:, None, 0, 0] * depths_j,\n",
    "        (corr_points_j[..., 1] - Ks_j[:, None, 1, 2]) / Ks_j[:, None, 1, 1] * depths_j,\n",
    "        depths_j\n",
    "    ], dim=-1)   # (N, P, 3)\n",
    "    world_coords_i = cam_coords_i @ cam2w_i[:, :3, :3].permute(0, 2, 1) + cam2w_i[:, None, :, 3]\n",
    "    world_coords_j = cam_coords_j @ cam2w_j[:, :3, :3].permute(0, 2, 1) + cam2w_j[:, None, :, 3]\n",
    "\n",
    "    corr_weights_mask = (corr_weights.squeeze(-1) > 0.1) & (depths_i.squeeze() > 0) & (depths_j.squeeze() > 0) & \\\n",
    "                        (corr_points_i_normalized[..., 0] >= -1.0) & (corr_points_i_normalized[..., 0] <= 1.0) & \\\n",
    "                        (corr_points_i_normalized[..., 1] >= -1.0) & (corr_points_i_normalized[..., 1] <= 1.0) & \\\n",
    "                        (corr_points_j_normalized[..., 0] >= -1.0) & (corr_points_j_normalized[..., 0] <= 1.0) & \\\n",
    "                        (corr_points_j_normalized[..., 1] >= -1.0) & (corr_points_j_normalized[..., 1] <= 1.0)\n",
    "    \n",
    "    rgbs_i = (rgbs_i.cpu().numpy() * 255).astype(np.uint8)\n",
    "    rgbs_j = (rgbs_j.cpu().numpy() * 255).astype(np.uint8)\n",
    "    world_coords_i = world_coords_i.cpu().numpy().astype(np.float64)\n",
    "    world_coords_j = world_coords_j.cpu().numpy().astype(np.float64)\n",
    "    corr_points_i = corr_points_i.cpu().numpy()\n",
    "    corr_points_j = corr_points_j.cpu().numpy()\n",
    "\n",
    "    # Validation\n",
    "    # rgbs_i = rgbs_i[corr_weights_mask]\n",
    "    # rgbs_j = rgbs_j[corr_weights_mask]\n",
    "    # world_coords_i = world_coords_i[corr_weights_mask]\n",
    "    # world_coords_j = world_coords_j[corr_weights_mask]\n",
    "    # points_i = points_i[corr_weights_mask]\n",
    "    # points_j = points_j[corr_weights_mask]\n",
    "    \n",
    "    # rgbs_i = np.concatenate([rgbs_i, np.ones((rgbs_i.shape[0], 1), dtype=np.uint8) * 255], axis=-1)\n",
    "    # rgbs_j = np.concatenate([rgbs_j, np.ones((rgbs_j.shape[0], 1), dtype=np.uint8) * 255], axis=-1)\n",
    "\n",
    "    # trimesh.PointCloud(world_coords_i, colors=rgbs_i).export(\"./pcd_i.ply\")\n",
    "    # trimesh.PointCloud(world_coords_j, colors=rgbs_j).export(\"./pcd_j.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total points3D added:  1028397\n",
      "Total images added:  152\n",
      "Start bundle adjustment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I20250906 11:07:54.486351 49816 misc.cc:198] \n",
      "==============================================================================\n",
      "Global bundle adjustment\n",
      "==============================================================================\n",
      "I20250906 11:15:19.884331 49816 misc.cc:205] \n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "I20250906 11:15:19.884440 49816 bundle_adjustment.cc:942] \n",
      "    Residuals : 4113588\n",
      "   Parameters : 3086098\n",
      "   Iterations : 101\n",
      "         Time : 442.016 [s]\n",
      " Initial cost : 11.7961 [px]\n",
      "   Final cost : 2.37967 [px]\n",
      "  Termination : No convergence\n",
      "\n",
      "I20250906 11:15:19.884450 49816 timer.cc:91] Elapsed time: 7.423 [minutes]\n"
     ]
    }
   ],
   "source": [
    "# reconstruction, valid_track_mask = batch_np_matrix_to_pycolmap_xfeat(\n",
    "#     points_3d,\n",
    "#     extrinsic[inverse_idx],\n",
    "#     intrinsic[inverse_idx],\n",
    "#     pred_tracks,\n",
    "#     image_size,\n",
    "#     masks=track_mask,\n",
    "#     max_reproj_error=8,\n",
    "#     shared_camera=True,\n",
    "#     camera_type=\"SIMPLE_PINHOLE\",\n",
    "#     points_rgb=points_rgb,\n",
    "# )\n",
    "\n",
    "max_reproj_error = 8\n",
    "shared_camera = True\n",
    "camera_type = \"PINHOLE\"\n",
    "extra_params = None\n",
    "intrinsics = intrinsic\n",
    "extrinsics = extrinsic\n",
    "masks = corr_weights_mask\n",
    "image_size = np.array([images.shape[-1], images.shape[-2]])\n",
    "\n",
    "M, P = masks.shape\n",
    "N = len(intrinsics)\n",
    "assert len(extrinsics) == N\n",
    "assert len(indexes_i) == M\n",
    "assert len(indexes_j) == M\n",
    "assert masks is not None\n",
    "\n",
    "# Reconstruction object, following the format of PyCOLMAP/COLMAP\n",
    "reconstruction = pycolmap.Reconstruction()\n",
    "\n",
    "# Only add 3D points that have sufficient 2D points\n",
    "points_2D_dict = {}\n",
    "\n",
    "# for vidx in valid_idx:\n",
    "#     # Use RGB colors if provided, otherwise use zeros\n",
    "#     rgb = points_rgb[vidx] if points_rgb is not None else np.zeros(3)\n",
    "#     reconstruction.add_point3D(points3d[vidx], pycolmap.Track(), rgb)\n",
    "\n",
    "for m in range(M):\n",
    "    rgb_i = rgbs_i[m][masks[m]]\n",
    "    rgb_j = rgbs_j[m][masks[m]]\n",
    "    world_xyz_i = world_coords_i[m][masks[m]]\n",
    "    world_xyz_j = world_coords_j[m][masks[m]]\n",
    "    corr_point_i = corr_points_i[m][masks[m]]\n",
    "    corr_point_j = corr_points_j[m][masks[m]]\n",
    "\n",
    "    for idx in range(len(rgb_i)):\n",
    "        world_xyz = (world_xyz_i[idx]+world_xyz_j[idx])/2\n",
    "        point3D_id = reconstruction.add_point3D(world_xyz, pycolmap.Track(), rgb_i[idx])\n",
    "        index_i = indexes_i[m]\n",
    "        index_j = indexes_j[m]\n",
    "\n",
    "        if index_i not in points_2D_dict:\n",
    "            points_2D_dict[index_i] = []\n",
    "        if index_j not in points_2D_dict:\n",
    "            points_2D_dict[index_j] = []\n",
    "        points_2D_dict[index_i].append(pycolmap.Point2D(corr_point_i[idx], point3D_id))\n",
    "        points_2D_dict[index_j].append(pycolmap.Point2D(corr_point_j[idx], point3D_id))\n",
    "\n",
    "        track = reconstruction.points3D[point3D_id].track\n",
    "        track.add_element(index_i + 1, len(points_2D_dict[index_i])-1)\n",
    "        track.add_element(index_j + 1, len(points_2D_dict[index_j])-1)\n",
    "    \n",
    "camera = None\n",
    "# frame idx\n",
    "for fidx in range(N):\n",
    "    # set camera\n",
    "    if camera is None or (not shared_camera):\n",
    "        pycolmap_intri = _build_pycolmap_intri(fidx, intrinsics, camera_type, extra_params)\n",
    "\n",
    "        camera = pycolmap.Camera(\n",
    "            model=camera_type, width=image_size[0], height=image_size[1], params=pycolmap_intri, camera_id=fidx + 1\n",
    "        )\n",
    "\n",
    "        # add camera\n",
    "        reconstruction.add_camera(camera)\n",
    "\n",
    "    # set image\n",
    "    cam_from_world = pycolmap.Rigid3d(\n",
    "        pycolmap.Rotation3d(extrinsics[fidx][:3, :3]), extrinsics[fidx][:3, 3]\n",
    "    )  # Rot and Trans\n",
    "\n",
    "    image = pycolmap.Image(\n",
    "        id=fidx + 1, name=f\"image_{fidx + 1}\", camera_id=camera.camera_id, cam_from_world=cam_from_world\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        image.points2D = pycolmap.ListPoint2D(points_2D_dict[fidx])\n",
    "        image.registered = True\n",
    "    except:\n",
    "        print(f\"frame {fidx + 1} is out of BA\")\n",
    "        image.registered = False\n",
    "\n",
    "    # add image\n",
    "    reconstruction.add_image(image)\n",
    "\n",
    "print(\"Total points3D added: \", len(reconstruction.points3D))\n",
    "print(\"Total images added: \", len(reconstruction.images))\n",
    "\n",
    "# Run bundle adjustment\n",
    "print(\"Start bundle adjustment...\")\n",
    "ba_options = pycolmap.BundleAdjustmentOptions()\n",
    "pycolmap.bundle_adjustment(reconstruction, ba_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving reconstruction to ./sparse/0\n"
     ]
    }
   ],
   "source": [
    "reconstruction = colmap_utils.rename_colmap_recons_and_rescale_camera(\n",
    "    reconstruction,\n",
    "    base_image_path_list,\n",
    "    original_coords.cpu().numpy(),\n",
    "    img_size=(imsizes[0], imsizes[1]),\n",
    "    shift_point2d_to_original_res=True,\n",
    "    shared_camera=shared_camera,\n",
    ")\n",
    "\n",
    "print(f\"Saving reconstruction to ./sparse/0\")\n",
    "sparse_reconstruction_dir = os.path.join(\"./sparse/0\")\n",
    "os.makedirs(sparse_reconstruction_dir, exist_ok=True)\n",
    "reconstruction.write(sparse_reconstruction_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    --  Umeyama Scale:  0.13922844999466655\n",
      "    --  Umeyama Rotation: \n",
      " [[ 0.83793526 -0.13362013  0.52915988]\n",
      " [ 0.14918797  0.98871772  0.01342266]\n",
      " [-0.52498332  0.06769696  0.84841599]]\n",
      "    --  Umeyama Translation: \n",
      " [[-0.1057633 ]\n",
      " [ 0.01605802]\n",
      " [-0.20710195]]\n",
      "    --  Pair Rot   Error (Deg) of Vanilla:      10.51\n",
      "    --  Pair Trans Error (Deg) of Vanilla:      23.12\n",
      "    --  AUC at 30: 0.3119\n"
     ]
    }
   ],
   "source": [
    "cameras_ba = colmap_utils.read_cameras_binary(os.path.join(\"./sparse/0\", \"cameras.bin\"))\n",
    "images_ba = colmap_utils.read_images_binary(os.path.join(\"./sparse/0\", \"images.bin\"))\n",
    "\n",
    "images_ba_updated = {id: images_ba[id] for id in list(images_gt_keys)}\n",
    "translation_ba = torch.tensor([image.tvec for image in images_ba_updated.values()], device=device)\n",
    "rotation_ba = torch.tensor([colmap_utils.qvec2rotmat(image.qvec) for image in images_ba_updated.values()], device=device)\n",
    "\n",
    "# pred w2c\n",
    "ba_se3 = torch.eye(4, device=device).unsqueeze(0).repeat(len(images_ba_updated), 1, 1)\n",
    "ba_se3[:, :3, :3] = rotation_ba\n",
    "ba_se3[:, 3, :3] = translation_ba\n",
    "\n",
    "results = evaluate_auc(gt_se3, ba_se3, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vggt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
